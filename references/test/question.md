Привет,

Вот краткое описание нашей архитектуры (схемку приложил):

Патенты слишком большие (70 тыс. - 500 тыс. токенов), поэтому всё передаем небольшими кусками.

### Первый агент (Bioactivity extractor)
Ищет биоактивности в тексте. Сначала происходит поиск по ключевым словам с помощью регулярного выражения: содержание IC50, Ki, Kd и других вариантов написания.

Если активность была найдена в:
1)  Таблице - LLM подается сама таблица + контекст патента (например, 3 абзаца до таблицы, 2 абзаца после таблицы). Если таблица слишком большая - она делится на части (например, по 12 строчек). Таблица в xml, мы можем сохранить header и проходится по строкам.  

2) Тексте - подается абзац, содержащий информацию о связи.

В обоих случаях просим LLM вывести биоактивность в таком формате:
{
  [
    "molecule_name": "",
    "protein_target_name": "",
    "organism": "",
    "binding_metric": "",
    "value": "",
    "unit": ""
  ],
...
}


### Второй агент (Alias resolver)

В текстах часто вместо имени молекулы используется алиас (Например "Compound 1", "Example 5"). Второй агент  переводит такие обозначения в химические названия. С помощью регулярного выражения и некоторых эвристик находим упоминание алиаса (например "Compound 1") и передаем LLM вместе контекстом и просим соотнести с настоящим химическим названием (и chemical id, если оно имеется):
{
    "true_name": "IUPAC name or null, if not found",
    "chemical_id": "Chemical ID number or null, if not found"
}

### Третий агент (Protein resolver)

Недавно добавили агента для более умного разрешения имен белков, так как была проблема с тем что что-то не находилось или находилось неправильно.
На вход третьему агенту подается имя белка, на выходе ожидаем соответсвующий ген. По гену определяем uniprot имя белка. Третий агент использует более умную llm qwen/qwen3-max. Агент пока не обращается в интернет, но по первым впечатлениям даже так способен определить ген.

---

Вопросы:

1. Первый агент получается довольно перегруженным, ему приходится:
 a) Следовать довольно большому количеству правил (10 на данный момент).
 б) Выводить по 10+ связей, каждая связь содержит 6-7 полей (molecule_name, protein_target_name и т.д.)
 в) Искать информацию контексте, который может не иметь отношения к искомым данным.
В данный момент модель (Qwen3 235B A22B Instruct 2507) справляется с работой, но добавление новых правил извлечения или дополнительного контекста может ухудшить результат.


Пример ухудшения результата:

Тест: Поиск по патентам, обработанным в bindingdb.
Total binding: найдено связей.
New binding: есть у нас, нет в binding db.
Exact match by metric: полное совпадение с binding db.
No Exact match by metric: совпало по inchi_key и sequence, но не по метрике связывания.
Not found binding: есть в binding db, нет у нас.

- Как работает сейчас:
Total binding: 13507
New binding: 4616
Exact match by metric: 7123
No Exact match by metric: 1886
Not found binding: 4566

-  Добавили вывод assay_type (новое поле):
Total binding: 11201
New binding: 3817
Exact match by metric: 5795
No Exact match by metric: 1734
Not found binding: 5134


Варианты решения этой проблемы, которые придумали мы:
 1) Добавить предобработку контекста с помощью LLM: отбрасывать лишнюю информацию + summarization.
 2) Использовать thinking модель.


2. В каком виде лучше передавать таблицы? В оригинальном документе - кривой xml, в котором неправильно используются теги. На данный момент передаются в таком проприетарном виде:

"table_title": "TABLE 2  MAPK and PI3Kalpha kinase assay test results",
"head_block": [
    [
        "Compound",
        "Erk2",
        "PI3Kalpha",
        "p38alpha",
        "Jnk1 + Jnk2"
    ],
    ...
],
"block_1": [
    [
        "1",
        "1",
        "0.9",
        ">31.6",
        ">31.6"
    ],
    [
        "25",
        "0.076",
        "1.5",
        ">100",
        ">31.6"
    ],
    ...
]
"block_1": [...]

3. Какую модель лучше использовать? (сейчас Qwen3 235B A22B Instruct 2507 т.к. дешевая, достаточно умная и хорошо следует инструкциям)

4. Какую температуру? (сейчас 0.1)

5. Какими инструментами пользоваться для добавления поисковых интернет-запросов в контекст модели? Может есть готовые решения? (может понадобится для поиска белков)

image.png